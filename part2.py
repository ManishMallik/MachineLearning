# -*- coding: utf-8 -*-
"""part2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-0YA-wHUxkGN7VOdPoGl8uYtQBqTH9-7
"""



"""Using the libraries:

Will need data processing beforehand
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# if needed, split train and test
import seaborn as sns
from sklearn.metrics import r2_score
#from sklearn.datasets import load_boston
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler
#correlation analysis
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"
column_names = ["MPG", "Cylinders", "Displacement", "Horsepower", "Weight", "Acceleration", "Model Year", "Origin", "Car Name"]
data = pd.read_csv(url, names=column_names, delim_whitespace=True)
data = data.sample(frac=1)
#data = pd.read_csv("machine.data.txt", sep=",")
print(data)
# Calculate the correlation matrix
correlation_matrix = data.corr()

# Extract correlations with 'MPG' and sort them in descending order
correlations_with_mpg = correlation_matrix["MPG"].sort_values(ascending=False)

# Print the correlations
print(correlations_with_mpg)

"""Choosing the features (we will use 6 features: horsepower and car name not included)"""

#X = data[['MMIN', 'MMAX', 'CHMIN', 'CHMAX']].to_numpy()
# X = data[['CACH', 'CHMIN', 'CHMAX', 'PRP']].to_numpy()
X = data[['Cylinders', 'Displacement', 'Weight', 'Acceleration', 'Model Year', 'Origin']]
rows = data.shape[0]
ratio = 0.8
index = int(rows * ratio)
print(X)
# X_MYCT = data['MYCT']
# X_CACH = data['CACH']
# X_MMIN = data['MMIN']
# X_MMAX = data['MMAX']
# X_CHMIN = data['CHMIN']
# X_CHMAX = data['CHMAX']
# X_weight = data['Weight']
# X_accel = data['Acceleration']
y = data['MPG']
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X[0:index]
y_train = y[0:index]
X_test = X[index:]
y_test = y[index:]
X_train = np.array(X_train)
y_train = np.array(y_train)
X_test = np.array(X_test)
y_test = np.array(y_test)

#X = data[['X1 transaction date']]
#y = data['Y house price of unit area']
print(type(data))
print(type(X))
# plt.scatter(X_MMIN, y, s=5, label = 'MMIN')
# plt.scatter(X_MMAX, y, s=5, label = 'MMAX')
# # plt.scatter(X_weight, y, s=5, label = 'Weight')
# # plt.scatter(X_accel, y, s=5, label = 'Acceleration')
# plt.legend(fontsize=15)
# plt.xlabel('Weight and Acceleration', fontsize=15)
# plt.ylabel('ERP', fontsize=15)
# plt.legend()
# plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)

#####

# linear model
model = LinearRegression()

# training (this assumes X and Y is training and X_test is the test data and Y_test is also)
model.fit(X, y)

# predictions
y_train_pred = model.predict(X_train)

# testing (evaluating)
mse = mean_squared_error(y_train, y_train_pred)

print(f"MSE Train: {mse}")

# predictions
y_test_pred = model.predict(X_test)

# testing (evaluating)
mse = mean_squared_error(y_test, y_test_pred)

print(f"MSE Test: {mse}")

model.coef_

print(r2_score(y_train, y_train_pred))
print(r2_score(y_test, y_test_pred))